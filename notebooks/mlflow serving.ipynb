{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 2.7.1\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow.pyfunc.loaded_model:\n",
      "  artifact_path: model\n",
      "  flavor: mlflow.sklearn\n",
      "  run_id: b33f0afd99c449d699ad35a803e71e6d\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:1234')\n",
    "\n",
    "model_name = \"GradientBoostingRegressor\"\n",
    "model_stage = \"Staging\"\n",
    "\n",
    "model_uri = f\"models:/{model_name}/{model_stage}\"\n",
    "mlflow_model = mlflow.pyfunc.load_model(model_uri=model_uri)\n",
    "\n",
    "print(mlflow_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_1 = pd.DataFrame({\n",
    " 'trip_miles': [2.71],\n",
    " 'trip_time': [796.0],\n",
    " 'access_a_ride_flag': [' '],\n",
    " 'request_datetime_hour': [11],\n",
    " 'request_datetime_day': ['Friday'],\n",
    " 'request_datetime_month': ['January'],\n",
    " 'duration_minutes': [13.266666666666667],\n",
    " 'wait_time_minutes': [1.3833333333333333],\n",
    " 'service_time_minutes': [16.366666666666667],\n",
    " 'on_scene_datetime_hour': [11],\n",
    " 'on_scene_datetime_day': ['Friday'],\n",
    " 'on_scene_datetime_month': ['January'],\n",
    " 'pickup_datetime_hour': [11],\n",
    " 'pickup_datetime_day': ['Friday'],\n",
    " 'pickup_datetime_month': ['January'],\n",
    " 'dropoff_datetime_hour': [11],\n",
    " 'dropoff_datetime_day': ['Friday'],\n",
    " 'dropoff_datetime_month': ['January'],\n",
    " 'average_speed': [0.20427135678391958]\n",
    "})\n",
    "\n",
    "input_data_2 = pd.DataFrame({\n",
    " 'trip_miles': [3.5],\n",
    " 'trip_time': [850.0],\n",
    " 'access_a_ride_flag': ['Y'],\n",
    " 'request_datetime_hour': [14],\n",
    " 'request_datetime_day': ['Monday'],\n",
    " 'request_datetime_month': ['February'],\n",
    " 'duration_minutes': [14.166666666666666],\n",
    " 'wait_time_minutes': [1.6],\n",
    " 'service_time_minutes': [17.5],\n",
    " 'on_scene_datetime_hour': [14],\n",
    " 'on_scene_datetime_day': ['Monday'],\n",
    " 'on_scene_datetime_month': ['February'],\n",
    " 'pickup_datetime_hour': [14],\n",
    " 'pickup_datetime_day': ['Monday'],\n",
    " 'pickup_datetime_month': ['February'],\n",
    " 'dropoff_datetime_hour': [15],\n",
    " 'dropoff_datetime_day': ['Monday'],\n",
    " 'dropoff_datetime_month': ['February'],\n",
    " 'average_speed': [0.24705882352941178]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "\n",
    "class Files:\n",
    "    \"\"\"Utility class for reading and loading files.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def read_yaml(file_path):\n",
    "        \"\"\"Load YAML file.\"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            return yaml.safe_load(file)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_pickle(pickle_path):\n",
    "        \"\"\"Load Pickle file.\"\"\"\n",
    "        with open(pickle_path, 'rb') as pickle_file:\n",
    "            return pickle.load(pickle_file)\n",
    "\n",
    "\n",
    "class ModelPredictor:\n",
    "    \"\"\"Class for loading the model and making predictions.\"\"\"\n",
    "\n",
    "    def __init__(self, _, X_scaler_path, y_scaler_path):\n",
    "        \"\"\"Initialize and load the model and scalers.\"\"\"\n",
    "        self.model = mlflow_model\n",
    "        self.X_scaler = Files.load_pickle(X_scaler_path)\n",
    "        self.y_scaler = Files.load_pickle(y_scaler_path)\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"Predict the output for given data.\"\"\"\n",
    "        data[continuous_cols] = self.X_scaler.transform(data[continuous_cols])\n",
    "        prediction = self.model.predict(data)\n",
    "        inverse_transformed_y = self.y_scaler.inverse_transform(prediction.reshape(-1, 1))\n",
    "        return inverse_transformed_y\n",
    "\n",
    "\n",
    "def map_data_to_df(input_data):\n",
    "    \"\"\"Map input data to a DataFrame in the expected format.\"\"\"\n",
    "    # Initialize DataFrame with zeros\n",
    "    df_mapped = pd.DataFrame(columns=keys_list, index=[0]).fillna(0)\n",
    "\n",
    "    # Map values\n",
    "    for key, value in input_data.items():\n",
    "        if key in df_mapped.columns:\n",
    "            df_mapped[key] = value\n",
    "\n",
    "    # One-hot encode days\n",
    "    days_columns = [\n",
    "        'request_datetime_day', 'on_scene_datetime_day',\n",
    "        'pickup_datetime_day', 'dropoff_datetime_day'\n",
    "    ]\n",
    "    for col in days_columns:\n",
    "        if col in input_data:\n",
    "            column_name = f\"{col}_{input_data[col]}\"\n",
    "            if column_name in df_mapped.columns:\n",
    "                df_mapped[column_name] = 1\n",
    "\n",
    "    # Set data types\n",
    "    for col in continuous_cols:\n",
    "        if col in df_mapped.columns:\n",
    "            df_mapped[col] = df_mapped[col].astype(float)\n",
    "    for col in categorical_cols:\n",
    "        if col in df_mapped.columns:\n",
    "            df_mapped[col] = df_mapped[col].astype(str) if \"day\" in col else df_mapped[col].astype(int)\n",
    "\n",
    "    return df_mapped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perform_prediction(data):\n",
    "    \"\"\"Main function to load model and make predictions.\"\"\"\n",
    "    try:\n",
    "        config = Files.read_yaml('/mnt/hgfs/DS/NYC MLOPS/parameters.yaml')\n",
    "        model_file_path = os.path.join(os.path.dirname(cwd),config['prediction_app']['model'])\n",
    "        X_scaler_path = os.path.join(os.path.dirname(cwd),config['prediction_app']['scaler'], \"X_scaler.pkl\")\n",
    "        y_scaler_path= os.path.join(os.path.dirname(cwd),config['prediction_app']['scaler'], \"y_scaler.pkl\")\n",
    "\n",
    "        predictor = ModelPredictor(model_file_path, X_scaler_path, y_scaler_path)\n",
    "        prediction = predictor.predict(data)\n",
    "        \n",
    "\n",
    "        logging.info(f\"Prediction result: {prediction}\")\n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main_prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "#> Mapping\n",
    "\n",
    "keys_list = [\n",
    "    'trip_miles', 'trip_time', 'duration_minutes', 'wait_time_minutes', 'service_time_minutes', 'average_speed', \n",
    "    'request_datetime_hour', 'on_scene_datetime_hour', 'pickup_datetime_hour', 'dropoff_datetime_hour',\n",
    "    'request_datetime_day_Friday', 'request_datetime_day_Monday', \n",
    "    'request_datetime_day_Saturday', 'request_datetime_day_Sunday', 'request_datetime_day_Thursday', \n",
    "    'request_datetime_day_Tuesday', 'request_datetime_day_Wednesday', 'on_scene_datetime_day_Friday', \n",
    "    'on_scene_datetime_day_Monday', 'on_scene_datetime_day_Saturday', 'on_scene_datetime_day_Sunday', \n",
    "    'on_scene_datetime_day_Thursday', 'on_scene_datetime_day_Tuesday', 'on_scene_datetime_day_Wednesday', \n",
    "    'pickup_datetime_day_Friday', 'pickup_datetime_day_Monday', 'pickup_datetime_day_Saturday', \n",
    "    'pickup_datetime_day_Sunday', 'pickup_datetime_day_Thursday', 'pickup_datetime_day_Tuesday', \n",
    "    'pickup_datetime_day_Wednesday', 'dropoff_datetime_day_Friday', 'dropoff_datetime_day_Monday', \n",
    "    'dropoff_datetime_day_Saturday', 'dropoff_datetime_day_Sunday', 'dropoff_datetime_day_Thursday', \n",
    "    'dropoff_datetime_day_Tuesday', 'dropoff_datetime_day_Wednesday'\n",
    "]\n",
    "\n",
    "# Columns\n",
    "continuous_cols = [\n",
    "    'trip_miles', 'trip_time', 'duration_minutes',\n",
    "    'wait_time_minutes', 'service_time_minutes', 'average_speed'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'request_datetime_hour', 'request_datetime_day', 'request_datetime_month',\n",
    "    'on_scene_datetime_hour', 'on_scene_datetime_day', 'on_scene_datetime_month',\n",
    "    'pickup_datetime_hour', 'pickup_datetime_day', 'pickup_datetime_month',\n",
    "    'dropoff_datetime_hour', 'dropoff_datetime_day', 'dropoff_datetime_month'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.36490738]]\n"
     ]
    }
   ],
   "source": [
    "df_mapped = map_data_to_df(input_data_1)\n",
    "pred=perform_prediction(df_mapped)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.4006366]]\n"
     ]
    }
   ],
   "source": [
    "df_mapped = map_data_to_df(input_data_2)\n",
    "pred=perform_prediction(df_mapped)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
